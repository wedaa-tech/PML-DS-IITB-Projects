#!/bin/bash
# ===========================================================
# ğŸï¸  YouTube â†’ ML Dataset Generator (High Quality + Metadata)
# Author: ChatGPT (Cordial Dude edition)
# ===========================================================
# Features:
# âœ… Stable (downloads video before processing)
# âœ… Captures frames at user-defined interval
# âœ… High quality (q:v=2)
# âœ… Creates train/test split
# âœ… Auto-generates dataset_info.csv with metadata
# ===========================================================

# --- Config ---
BASE_DIR="frames_dataset"
TRAIN_DIR="$BASE_DIR/train"
TEST_DIR="$BASE_DIR/test"
TEMP_FILE="temp_youtube_video.mp4"
CSV_FILE="$BASE_DIR/dataset_info.csv"

# --- User Inputs ---
read -p "Enter YouTube video URL: " YT_URL
read -p "Enter time gap between frames (in seconds, e.g. 2): " GAP
read -p "Enter total number of frames to capture (e.g. 300): " TOTAL_FRAMES

# --- Derived ---
FPS=$(awk "BEGIN {print 1/$GAP}")

# --- Ensure dependencies ---
if ! command -v yt-dlp &> /dev/null; then
    echo "Installing yt-dlp via Homebrew..."
    brew install yt-dlp
fi
if ! command -v ffmpeg &> /dev/null; then
    echo "Installing ffmpeg via Homebrew..."
    brew install ffmpeg
fi

# --- Prepare directories ---
mkdir -p "$TRAIN_DIR"
mkdir -p "$TEST_DIR"

# --- Step 1: Download video safely ---
echo "â¬‡ï¸  Downloading video locally for stable processing..."
yt-dlp -f "best[ext=mp4]" -o "$TEMP_FILE" --no-playlist "$YT_URL"

if [ ! -f "$TEMP_FILE" ]; then
    echo "âŒ Error: Video download failed."
    exit 1
fi

# --- Step 2: Extract frames ---
echo "ğŸ¥ Extracting frames every $GAP seconds (FPS=$FPS)..."
ffmpeg -hide_banner -loglevel error -i "$TEMP_FILE" -vf "fps=$FPS" -frames:v "$TOTAL_FRAMES" -q:v 2 "$BASE_DIR/frame_%04d.png"

if [ $? -ne 0 ]; then
    echo "âŒ Frame extraction failed."
    exit 1
fi

# --- Step 3: Train/Test split ---
echo "ğŸ“‚ Splitting frames into train/test sets..."
TOTAL=$(ls "$BASE_DIR"/*.png | wc -l | tr -d ' ')
TEST_COUNT=$((TOTAL / 5))  # 20% test
COUNT=0

for IMG in "$BASE_DIR"/*.png; do
    if [ $COUNT -lt $TEST_COUNT ]; then
        mv "$IMG" "$TEST_DIR/"
    else
        mv "$IMG" "$TRAIN_DIR/"
    fi
    COUNT=$((COUNT + 1))
done

# --- Step 4: Generate dataset_info.csv ---
echo "ğŸ§¾ Generating dataset_info.csv..."

VIDEO_TITLE=$(yt-dlp --get-title "$YT_URL")
DATE_CAPTURED=$(date "+%Y-%m-%d %H:%M:%S")

echo "image_path,set_type,timestamp,video_title,source_url" > "$CSV_FILE"

for IMG in "$TRAIN_DIR"/*.png; do
    echo "$IMG,train,$DATE_CAPTURED,\"$VIDEO_TITLE\",$YT_URL" >> "$CSV_FILE"
done
for IMG in "$TEST_DIR"/*.png; do
    echo "$IMG,test,$DATE_CAPTURED,\"$VIDEO_TITLE\",$YT_URL" >> "$CSV_FILE"
done

# --- Step 5: Cleanup ---
rm -f "$TEMP_FILE"

# --- Summary ---
echo "âœ… Done!"
echo "ğŸ“Š Metadata file: $CSV_FILE"
echo "ğŸ“ Train images: $(ls -1 $TRAIN_DIR | wc -l)"
echo "ğŸ“ Test images:  $(ls -1 $TEST_DIR | wc -l)"
echo "-----------------------------------------------------------"
echo "ğŸ¯ High-quality frames captured at every $GAP seconds"
echo "ğŸ–¼ï¸ All frames are PNGs â€” full resolution"
echo "ğŸ“˜ CSV file includes paths, timestamps, and source info"
echo "-----------------------------------------------------------"
